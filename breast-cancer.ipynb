{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import *\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'ID',\n",
    "    'diagnosis',\n",
    "    'radius_m',\n",
    "    'texture_m',\n",
    "    'perimeter_m',\n",
    "    'area_m',\n",
    "    'smoothness_m',\n",
    "    'compactness_m',\n",
    "    'concavity_m',\n",
    "    'concave_points_m',\n",
    "    'symmetry_m',\n",
    "    'fractal_dimension_m',\n",
    "    'radius_se',\n",
    "    'texture_se',\n",
    "    'perimeter_se',\n",
    "    'area_se',\n",
    "    'smoothness_se',\n",
    "    'compactness_se',\n",
    "    'concavity_se',\n",
    "    'concave_points_se',\n",
    "    'symmetry_se',\n",
    "    'fractal_dimension_se',\n",
    "    'radius_w',\n",
    "    'texture_w',\n",
    "    'perimeter_w',\n",
    "    'area_w',\n",
    "    'smoothness_w',\n",
    "    'compactness_w',\n",
    "    'concavity_w',\n",
    "    'concave_points_w',\n",
    "    'symmetry_w',\n",
    "    'fractal_dimension_w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize(obj):\n",
    "    with open('pickle_files/'+namestr(obj)+'.pickle','wb') as f:\n",
    "        pk.dump(obj,f,pk.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def load(obj):\n",
    "    with open('pickle_files/'+obj+'.pickle','rb') as f:\n",
    "        return pk.load(f)\n",
    "\n",
    "def namestr(obj):\n",
    "    g = globals()\n",
    "    return [name for name in g if g[name] is obj][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset from .data file"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('wdbc.data') as file:\n",
    "    l = file.read().splitlines()\n",
    "    l = [i.split(',') for i in l]\n",
    "    data_set = pd.DataFrame(l, columns=cols)\n",
    "    for i in data_set:\n",
    "        data_set[i] = pd.to_numeric(data_set[i],errors='ignore')\n",
    "    \n",
    "    data_set = data_set.sample(frac=1).reset_index(drop=True)\n",
    "    serialize(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_set = load('data_set')\n",
    "\n",
    "# M => 1, B => 0\n",
    "data_set.replace('B', 0, inplace=True)\n",
    "data_set.replace('M', 1, inplace=True)\n",
    "\n",
    "X = data_set.iloc[:,2:]\n",
    "y = data_set.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_m</th>\n",
       "      <th>texture_m</th>\n",
       "      <th>perimeter_m</th>\n",
       "      <th>area_m</th>\n",
       "      <th>smoothness_m</th>\n",
       "      <th>compactness_m</th>\n",
       "      <th>concavity_m</th>\n",
       "      <th>concave_points_m</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_w</th>\n",
       "      <th>texture_w</th>\n",
       "      <th>perimeter_w</th>\n",
       "      <th>area_w</th>\n",
       "      <th>smoothness_w</th>\n",
       "      <th>compactness_w</th>\n",
       "      <th>concavity_w</th>\n",
       "      <th>concave_points_w</th>\n",
       "      <th>symmetry_w</th>\n",
       "      <th>fractal_dimension_w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89143601</td>\n",
       "      <td>0</td>\n",
       "      <td>11.37</td>\n",
       "      <td>18.89</td>\n",
       "      <td>72.17</td>\n",
       "      <td>396.0</td>\n",
       "      <td>0.08713</td>\n",
       "      <td>0.05008</td>\n",
       "      <td>0.02399</td>\n",
       "      <td>0.02173</td>\n",
       "      <td>...</td>\n",
       "      <td>12.36</td>\n",
       "      <td>26.14</td>\n",
       "      <td>79.29</td>\n",
       "      <td>459.3</td>\n",
       "      <td>0.11180</td>\n",
       "      <td>0.09708</td>\n",
       "      <td>0.07529</td>\n",
       "      <td>0.06203</td>\n",
       "      <td>0.3267</td>\n",
       "      <td>0.06994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>871641</td>\n",
       "      <td>0</td>\n",
       "      <td>11.08</td>\n",
       "      <td>14.71</td>\n",
       "      <td>70.21</td>\n",
       "      <td>372.7</td>\n",
       "      <td>0.10060</td>\n",
       "      <td>0.05743</td>\n",
       "      <td>0.02363</td>\n",
       "      <td>0.02583</td>\n",
       "      <td>...</td>\n",
       "      <td>11.35</td>\n",
       "      <td>16.82</td>\n",
       "      <td>72.01</td>\n",
       "      <td>396.5</td>\n",
       "      <td>0.12160</td>\n",
       "      <td>0.08240</td>\n",
       "      <td>0.03938</td>\n",
       "      <td>0.04306</td>\n",
       "      <td>0.1902</td>\n",
       "      <td>0.07313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>858970</td>\n",
       "      <td>0</td>\n",
       "      <td>10.17</td>\n",
       "      <td>14.88</td>\n",
       "      <td>64.55</td>\n",
       "      <td>311.9</td>\n",
       "      <td>0.11340</td>\n",
       "      <td>0.08061</td>\n",
       "      <td>0.01084</td>\n",
       "      <td>0.01290</td>\n",
       "      <td>...</td>\n",
       "      <td>11.02</td>\n",
       "      <td>17.45</td>\n",
       "      <td>69.86</td>\n",
       "      <td>368.6</td>\n",
       "      <td>0.12750</td>\n",
       "      <td>0.09866</td>\n",
       "      <td>0.02168</td>\n",
       "      <td>0.02579</td>\n",
       "      <td>0.3557</td>\n",
       "      <td>0.08020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89827</td>\n",
       "      <td>0</td>\n",
       "      <td>11.06</td>\n",
       "      <td>14.96</td>\n",
       "      <td>71.49</td>\n",
       "      <td>373.9</td>\n",
       "      <td>0.10330</td>\n",
       "      <td>0.09097</td>\n",
       "      <td>0.05397</td>\n",
       "      <td>0.03341</td>\n",
       "      <td>...</td>\n",
       "      <td>11.92</td>\n",
       "      <td>19.90</td>\n",
       "      <td>79.76</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.14180</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.22990</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.3301</td>\n",
       "      <td>0.09080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>904689</td>\n",
       "      <td>0</td>\n",
       "      <td>12.96</td>\n",
       "      <td>18.29</td>\n",
       "      <td>84.18</td>\n",
       "      <td>525.2</td>\n",
       "      <td>0.07351</td>\n",
       "      <td>0.07899</td>\n",
       "      <td>0.04057</td>\n",
       "      <td>0.01883</td>\n",
       "      <td>...</td>\n",
       "      <td>14.13</td>\n",
       "      <td>24.61</td>\n",
       "      <td>96.31</td>\n",
       "      <td>621.9</td>\n",
       "      <td>0.09329</td>\n",
       "      <td>0.23180</td>\n",
       "      <td>0.16040</td>\n",
       "      <td>0.06608</td>\n",
       "      <td>0.3207</td>\n",
       "      <td>0.07247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>855625</td>\n",
       "      <td>1</td>\n",
       "      <td>19.07</td>\n",
       "      <td>24.81</td>\n",
       "      <td>128.30</td>\n",
       "      <td>1104.0</td>\n",
       "      <td>0.09081</td>\n",
       "      <td>0.21900</td>\n",
       "      <td>0.21070</td>\n",
       "      <td>0.09961</td>\n",
       "      <td>...</td>\n",
       "      <td>24.09</td>\n",
       "      <td>33.17</td>\n",
       "      <td>177.40</td>\n",
       "      <td>1651.0</td>\n",
       "      <td>0.12470</td>\n",
       "      <td>0.74440</td>\n",
       "      <td>0.72420</td>\n",
       "      <td>0.24930</td>\n",
       "      <td>0.4670</td>\n",
       "      <td>0.10380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>892604</td>\n",
       "      <td>0</td>\n",
       "      <td>12.46</td>\n",
       "      <td>19.89</td>\n",
       "      <td>80.43</td>\n",
       "      <td>471.3</td>\n",
       "      <td>0.08451</td>\n",
       "      <td>0.10140</td>\n",
       "      <td>0.06830</td>\n",
       "      <td>0.03099</td>\n",
       "      <td>...</td>\n",
       "      <td>13.46</td>\n",
       "      <td>23.07</td>\n",
       "      <td>88.13</td>\n",
       "      <td>551.3</td>\n",
       "      <td>0.10500</td>\n",
       "      <td>0.21580</td>\n",
       "      <td>0.19040</td>\n",
       "      <td>0.07625</td>\n",
       "      <td>0.2685</td>\n",
       "      <td>0.07764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>924632</td>\n",
       "      <td>0</td>\n",
       "      <td>12.88</td>\n",
       "      <td>28.92</td>\n",
       "      <td>82.50</td>\n",
       "      <td>514.3</td>\n",
       "      <td>0.08123</td>\n",
       "      <td>0.05824</td>\n",
       "      <td>0.06195</td>\n",
       "      <td>0.02343</td>\n",
       "      <td>...</td>\n",
       "      <td>13.89</td>\n",
       "      <td>35.74</td>\n",
       "      <td>88.84</td>\n",
       "      <td>595.7</td>\n",
       "      <td>0.12270</td>\n",
       "      <td>0.16200</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.06493</td>\n",
       "      <td>0.2372</td>\n",
       "      <td>0.07242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>911320502</td>\n",
       "      <td>0</td>\n",
       "      <td>13.17</td>\n",
       "      <td>18.22</td>\n",
       "      <td>84.28</td>\n",
       "      <td>537.3</td>\n",
       "      <td>0.07466</td>\n",
       "      <td>0.05994</td>\n",
       "      <td>0.04859</td>\n",
       "      <td>0.02870</td>\n",
       "      <td>...</td>\n",
       "      <td>14.90</td>\n",
       "      <td>23.89</td>\n",
       "      <td>95.10</td>\n",
       "      <td>687.6</td>\n",
       "      <td>0.12820</td>\n",
       "      <td>0.19650</td>\n",
       "      <td>0.18760</td>\n",
       "      <td>0.10450</td>\n",
       "      <td>0.2235</td>\n",
       "      <td>0.06925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>875263</td>\n",
       "      <td>1</td>\n",
       "      <td>12.34</td>\n",
       "      <td>26.86</td>\n",
       "      <td>81.15</td>\n",
       "      <td>477.4</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.13530</td>\n",
       "      <td>0.10850</td>\n",
       "      <td>0.04562</td>\n",
       "      <td>...</td>\n",
       "      <td>15.65</td>\n",
       "      <td>39.34</td>\n",
       "      <td>101.70</td>\n",
       "      <td>768.9</td>\n",
       "      <td>0.17850</td>\n",
       "      <td>0.47060</td>\n",
       "      <td>0.44250</td>\n",
       "      <td>0.14590</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.12050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  diagnosis  radius_m  texture_m  perimeter_m  area_m  \\\n",
       "0     89143601          0     11.37      18.89        72.17   396.0   \n",
       "1       871641          0     11.08      14.71        70.21   372.7   \n",
       "2       858970          0     10.17      14.88        64.55   311.9   \n",
       "3        89827          0     11.06      14.96        71.49   373.9   \n",
       "4       904689          0     12.96      18.29        84.18   525.2   \n",
       "..         ...        ...       ...        ...          ...     ...   \n",
       "564     855625          1     19.07      24.81       128.30  1104.0   \n",
       "565     892604          0     12.46      19.89        80.43   471.3   \n",
       "566     924632          0     12.88      28.92        82.50   514.3   \n",
       "567  911320502          0     13.17      18.22        84.28   537.3   \n",
       "568     875263          1     12.34      26.86        81.15   477.4   \n",
       "\n",
       "     smoothness_m  compactness_m  concavity_m  concave_points_m  ...  \\\n",
       "0         0.08713        0.05008      0.02399           0.02173  ...   \n",
       "1         0.10060        0.05743      0.02363           0.02583  ...   \n",
       "2         0.11340        0.08061      0.01084           0.01290  ...   \n",
       "3         0.10330        0.09097      0.05397           0.03341  ...   \n",
       "4         0.07351        0.07899      0.04057           0.01883  ...   \n",
       "..            ...            ...          ...               ...  ...   \n",
       "564       0.09081        0.21900      0.21070           0.09961  ...   \n",
       "565       0.08451        0.10140      0.06830           0.03099  ...   \n",
       "566       0.08123        0.05824      0.06195           0.02343  ...   \n",
       "567       0.07466        0.05994      0.04859           0.02870  ...   \n",
       "568       0.10340        0.13530      0.10850           0.04562  ...   \n",
       "\n",
       "     radius_w  texture_w  perimeter_w  area_w  smoothness_w  compactness_w  \\\n",
       "0       12.36      26.14        79.29   459.3       0.11180        0.09708   \n",
       "1       11.35      16.82        72.01   396.5       0.12160        0.08240   \n",
       "2       11.02      17.45        69.86   368.6       0.12750        0.09866   \n",
       "3       11.92      19.90        79.76   440.0       0.14180        0.22100   \n",
       "4       14.13      24.61        96.31   621.9       0.09329        0.23180   \n",
       "..        ...        ...          ...     ...           ...            ...   \n",
       "564     24.09      33.17       177.40  1651.0       0.12470        0.74440   \n",
       "565     13.46      23.07        88.13   551.3       0.10500        0.21580   \n",
       "566     13.89      35.74        88.84   595.7       0.12270        0.16200   \n",
       "567     14.90      23.89        95.10   687.6       0.12820        0.19650   \n",
       "568     15.65      39.34       101.70   768.9       0.17850        0.47060   \n",
       "\n",
       "     concavity_w  concave_points_w  symmetry_w  fractal_dimension_w  \n",
       "0        0.07529           0.06203      0.3267              0.06994  \n",
       "1        0.03938           0.04306      0.1902              0.07313  \n",
       "2        0.02168           0.02579      0.3557              0.08020  \n",
       "3        0.22990           0.10750      0.3301              0.09080  \n",
       "4        0.16040           0.06608      0.3207              0.07247  \n",
       "..           ...               ...         ...                  ...  \n",
       "564      0.72420           0.24930      0.4670              0.10380  \n",
       "565      0.19040           0.07625      0.2685              0.07764  \n",
       "566      0.24390           0.06493      0.2372              0.07242  \n",
       "567      0.18760           0.10450      0.2235              0.06925  \n",
       "568      0.44250           0.14590      0.3215              0.12050  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tp(y, p):\n",
    "    return sum(np.logical_and(y,p))\n",
    "\n",
    "def fp(y, p):\n",
    "    return sum(np.logical_and(np.logical_not(y),p))\n",
    "\n",
    "def tn(y, p):\n",
    "    return sum(np.logical_not(np.logical_or(y,p)))\n",
    "\n",
    "def fn(y, p):\n",
    "    return sum(np.logical_and(y,np.logical_not(p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_prediction):\n",
    "    return sum(np.logical_not(np.logical_xor(y_true, y_prediction)))/len(y_true)\n",
    "\n",
    "def precision(y_true, y_prediction):\n",
    "    true_positive  = tp(y_true, y_prediction)\n",
    "    false_positive = fp(y_true, y_prediction)\n",
    "    return true_positive / (true_positive + false_positive)\n",
    "\n",
    "def recall(y_true, y_prediction):\n",
    "    true_positive  = tp(y_true, y_prediction)\n",
    "    false_negative = fn(y_true, y_prediction)\n",
    "    return true_positive / (true_positive + false_negative)\n",
    "\n",
    "def specifity(y_true, y_prediction):\n",
    "    false_positive = fp(y_true, y_prediction)\n",
    "    true_negative  = tn(y_true, y_prediction)\n",
    "    return true_negative / (false_positive + true_negative)\n",
    "\n",
    "def roc_auc(y_true, y_prediction):\n",
    "    tpr = recall(y_true, y_prediction)\n",
    "    fpr = 1 - specifity(y_true, y_prediction)\n",
    "    return (tpr*fpr/2)+((tpr+1)/2)*(1-fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, x_train, y_train, x_test, y_test):\n",
    "    model.fit(x_train,y_train)\n",
    "    return model.predict(x_test)\n",
    "\n",
    "def score(y_test, prediction):\n",
    "    score = []\n",
    "    score.append(accuracy(y_test, prediction))\n",
    "    score.append(precision(y_test, prediction))\n",
    "    score.append(recall(y_test, prediction))\n",
    "    score.append(roc_auc(y_test, prediction))\n",
    "    return np.array(score)\n",
    "\n",
    "def score2(y_test, prediction):\n",
    "    score = []\n",
    "    score.append(accuracy_score(y_test, prediction))\n",
    "    score.append(precision_score(y_test, prediction))\n",
    "    score.append(recall_score(y_test, prediction))\n",
    "    score.append(roc_auc_score(y_test, prediction))\n",
    "    return np.array(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(X, y, n):\n",
    "    options = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        X_folds = np.array_split(X, n)\n",
    "        y_folds = np.array_split(y, n)\n",
    "        \n",
    "        x_test = X_folds.pop(i)\n",
    "        y_test = y_folds.pop(i)\n",
    "\n",
    "        options.append([pd.concat(X_folds),pd.concat(y_folds),x_test,y_test])\n",
    "        \n",
    "    return options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result(model, X, y, n_fold):\n",
    "    folds_option = cross_validation(X, y, n_fold)\n",
    "    scores = []\n",
    "    for i in folds_option:\n",
    "        if len(scores):\n",
    "            scores += score(i[3],predict(model, *i))\n",
    "        else:\n",
    "            scores = score(i[3],predict(model, *i))\n",
    "    scores /= n_fold\n",
    "    return {'accuracy' : scores[0], \n",
    "            'precision': scores[1], \n",
    "            'recall' : scores[2], \n",
    "            'auc' : scores[3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP: \n",
    "    \n",
    "    def __init__(self, \n",
    "                 num_perceptrons  = 128, \n",
    "                 activation       = tf.nn.relu, \n",
    "                 solver           = tf.train.AdamOptimizer, \n",
    "                 learning_rate    = .01, \n",
    "                 regularizer_rate = .1,\n",
    "                 epochs           = 15, \n",
    "                 dropout_rate     = .6):\n",
    "    \n",
    "        self.num_perceptrons  = num_perceptrons\n",
    "        self.activation       = activation\n",
    "        self.solver           = solver\n",
    "        self.learning_rate    = learning_rate\n",
    "        self.regularizer_rate = regularizer_rate\n",
    "        self.epochs           = epochs\n",
    "        self.dropout_rate     = dropout_rate\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        self.s = tf.get_default_session()\n",
    "        if not self.s:\n",
    "            self.s = tf.InteractiveSession()\n",
    "            \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        # initial data\n",
    "        X      = np.array(X)     \n",
    "        y      = np.array(y).reshape((-1,1))\n",
    "        self.X_input = tf.placeholder('float', shape=(None, X.shape[1]), name='X')\n",
    "        self.y_input = tf.placeholder('float', shape=(None, y.shape[1]), name='y')\n",
    "        self.drop_rate = tf.placeholder('float')\n",
    "        \n",
    "        # initialize weights & bias\n",
    "        weights_0 = tf.Variable(tf.random_normal([X.shape[1],self.num_perceptrons], \n",
    "                                                 stddev=(1/tf.sqrt(float(X.shape[1])))))\n",
    "        bias_0    = tf.Variable(tf.random_normal([self.num_perceptrons]))\n",
    "\n",
    "        weights_1 = tf.Variable(tf.random_normal([self.num_perceptrons,y.shape[1]], \n",
    "                                                 stddev=(1/tf.sqrt(float(self.num_perceptrons)))))\n",
    "        bias_1    = tf.Variable(tf.random_normal([y.shape[1]]))\n",
    "        \n",
    "        # define layers\n",
    "        hidden_output  = self.activation(tf.matmul(self.X_input, weights_0)+bias_0)\n",
    "        dropped_output = tf.nn.dropout(hidden_output, rate=self.drop_rate)\n",
    "\n",
    "        output         = tf.matmul(dropped_output,weights_1) + bias_1\n",
    "        mean, std      = tf.nn.moments(output,0)\n",
    "        self.predicted = tf.sigmoid((output - mean)/std)\n",
    "        \n",
    "        # optimization\n",
    "        loss      = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.predicted,\n",
    "                                                                              labels=self.y_input))\\\n",
    "        + self.regularizer_rate*(tf.reduce_sum(tf.square(bias_0)) + tf.reduce_sum(tf.square(bias_1)))\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(loss,var_list=[weights_0,\n",
    "                                                                                       weights_1,\n",
    "                                                                                       bias_0,\n",
    "                                                                                       bias_1])\n",
    "        # training\n",
    "        self.s.run(tf.global_variables_initializer())\n",
    "        for i in range(self.epochs):\n",
    "            self.s.run(optimizer, {self.X_input:X, self.y_input:y, self.drop_rate:self.dropout_rate})\n",
    "        \n",
    "\n",
    "        \n",
    "    def predict(self, x_test):\n",
    "        prediction = self.s.run(self.predicted, {self.X_input:x_test, self.drop_rate:0})\n",
    "        return np.where(prediction.reshape((-1,))>.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9560782487191428,\n",
       " 'precision': 0.9488142235968324,\n",
       " 'recall': 0.9203164950991038,\n",
       " 'auc': 0.9461525971904619}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result(LogisticRegression(max_iter=3000), X, y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9051234280391244,\n",
       " 'precision': 0.9552689520624303,\n",
       " 'recall': 0.7688482531960792,\n",
       " 'auc': 0.8746668422520214}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result(svm.SVC(), X, y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.934979040521658,\n",
       " 'precision': 0.9168221625118177,\n",
       " 'recall': 0.8984395314830097,\n",
       " 'auc': 0.9249874059782378}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result(MLPClassifier(max_iter = 400, activation='relu'), X, y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9086166744294364,\n",
       " 'precision': 0.9204437066280956,\n",
       " 'recall': 0.8186607595303247,\n",
       " 'auc': 0.8913214614322161}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result(MLP(),X,y,5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
